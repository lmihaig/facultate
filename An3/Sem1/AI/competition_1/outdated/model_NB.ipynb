{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pprint\n",
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
                "from sklearn.metrics import accuracy_score, f1_score\n",
                "from sklearn import preprocessing\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "import advertools as adv\n",
                "from sklearn.metrics import make_scorer, precision_score, recall_score\n",
                "from sklearn.model_selection import KFold, cross_validate\n",
                "pp = pprint.PrettyPrinter(indent=4, sort_dicts=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocess(data):\n",
                "    data.text = data.text.apply(lambda x: x.lower())\n",
                "    data.text = data.text.replace(r'\\s+|\\\\n', '', regex=True)\n",
                "    return data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  language                                               text    label\n",
                        "0    dansk   dette er et fremragende initiativ, og jeg stø...  Ireland\n",
                        "1    dansk   hr. formand, jeg er sikker på, at alle her er...  Ireland\n",
                        "2    dansk   hr. formand, folk på den nordlige halvkugle t...  England\n",
                        "3    dansk   hr. formand, med forbehold af nogle få ændrin...  England\n",
                        "4    dansk   - hr. formand, jeg må protestere mod den lemf...  England\n",
                        "                                                text\n",
                        "0   hr. formand, selv om vi i høj grad sympatiser...\n",
                        "1   quiero dejar constancia de mi apoyo a este in...\n",
                        "2   . – el comercio ilegal de riñones humanos se ...\n",
                        "3   signor presidente, per introdurre una nota di...\n",
                        "4   jeg stemte for meddelelsen af decharge til fæ...\n"
                    ]
                }
            ],
            "source": [
                "train_data = pd.read_csv(\"data/train_data.csv\")\n",
                "train_data = preprocess(train_data)\n",
                "print(train_data.head())\n",
                "\n",
                "test_data = pd.read_csv(\"data/test_data.csv\")\n",
                "test_data = preprocess(test_data)\n",
                "print(test_data.head())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "le = preprocessing.LabelEncoder()\n",
                "mappings = []\n",
                "for col in [\"language\", \"label\"]:\n",
                "    train_data[col] = le.fit_transform(train_data[col])\n",
                "    mappings.append(dict(zip(le.transform(le.classes_), le.classes_)))\n",
                "\n",
                "print(mappings)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "stop_words = []\n",
                "for key in [\"danish\", \"german\", \"dutch\", \"italian\", \"spanish\"]:\n",
                "    stop_words += list(adv.stopwords[key])\n",
                "\n",
                "# count_vec = TfidfVectorizer(stop_words=stop_words)\n",
                "count_vec = CountVectorizer(stop_words=stop_words)\n",
                "\n",
                "train_bow = count_vec.fit_transform(train_data.text)\n",
                "test_bow = count_vec.transform(test_data.text)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[0 1 1 ... 0 1 2]\n"
                    ]
                }
            ],
            "source": [
                "model = ComplementNB().fit(train_bow, train_data.label)\n",
                "predicted_labels = model.predict(test_bow)\n",
                "print(predicted_labels)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "id\n",
                            "1     England\n",
                            "2     Ireland\n",
                            "3     Ireland\n",
                            "4     England\n",
                            "5    Scotland\n",
                            "Name: label, dtype: object"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "final_data = {\"id\": test_data.index+1, \"label\": predicted_labels}\n",
                "\n",
                "submission = pd.DataFrame(data=final_data).set_index(\"id\")\n",
                "submission = submission.label.apply(lambda x: mappings[1][x])\n",
                "submission.to_csv(\"submissions/submission_NB.csv\")\n",
                "submission.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compare_models(_X, _y, models, _cv=5):\n",
                "\n",
                "    acc = []\n",
                "    _scoring = {'accuracy': make_scorer(accuracy_score),\n",
                "                'precision': make_scorer(precision_score, average='macro'),\n",
                "                'recall': make_scorer(recall_score, average='macro'),\n",
                "                'f1': make_scorer(f1_score, average='macro')\n",
                "                }\n",
                "\n",
                "    kfold = KFold(n_splits=10, shuffle=True, random_state=69420)\n",
                "    for model in models:\n",
                "        results = cross_validate(estimator=model,\n",
                "                                 X=_X,\n",
                "                                 y=_y,\n",
                "                                 cv=kfold,\n",
                "                                 scoring=_scoring,\n",
                "                                 return_train_score=True)\n",
                "\n",
                "        pp.pprint({\"Model\": type(model).__name__,\n",
                "                   \"Training Accuracy scores\": results['train_accuracy'],\n",
                "                   \"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
                "                   \"Training Precision scores\": results['train_precision'],\n",
                "                   \"Mean Training Precision\": results['train_precision'].mean(),\n",
                "                   \"Training Recall scores\": results['train_recall'],\n",
                "                   \"Mean Training Recall\": results['train_recall'].mean(),\n",
                "                   \"Training F1 scores\": results['train_f1'],\n",
                "                   \"Mean Training F1 Score\": results['train_f1'].mean(),\n",
                "                   \"Validation Accuracy scores\": results['test_accuracy'],\n",
                "                   \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
                "                   \"Validation Precision scores\": results['test_precision'],\n",
                "                   \"Mean Validation Precision\": results['test_precision'].mean(),\n",
                "                   \"Validation Recall scores\": results['test_recall'],\n",
                "                   \"Mean Validation Recall\": results['test_recall'].mean(),\n",
                "                   \"Validation F1 scores\": results['test_f1'],\n",
                "                   \"Mean Validation F1 Score\": results['test_f1'].mean()\n",
                "                   })\n",
                "        acc.append(results['test_f1'].mean()*100)\n",
                "    return acc\n",
                "\n",
                "\n",
                "models = [ComplementNB(), BernoulliNB(), MultinomialNB()]\n",
                "print(compare_models(train_bow, train_data.label, models))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Accuracy: 0.6904017320182824\n",
                        "F1 score: 0.6256641475662816\n"
                    ]
                }
            ],
            "source": [
                "X = train_bow\n",
                "y = train_data.label\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
                "\n",
                "model = ComplementNB().fit(X_train, y_train)\n",
                "y_pred = model.predict(X_test)\n",
                "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
                "print('F1 score: ', f1_score(y_test, y_pred, average=\"macro\"))\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.2 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.2"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
