{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import KFold\n",
                "from sklearn.metrics import accuracy_score, f1_score\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def log_entropy_weight(matrix):\n",
                "    if type(matrix) is not np.ndarray:\n",
                "        matrix = matrix.toarray()\n",
                "    normalized = matrix / (1 + np.sum(matrix, axis=0))\n",
                "    nr_docs, _ = matrix.shape\n",
                "    '''\n",
                "        g_i = 1 + sum     p_ij * log(p_ij + 1)   \n",
                "                 j=1,N  ------------------------\n",
                "                               log(N)                              \n",
                "    '''\n",
                "    entropy = 1 + np.sum(np.multiply(normalized, np.log(normalized + 1)), axis=0)/np.log(nr_docs)\n",
                "    '''\n",
                "        logent_ij = gi * log(tf_ij + 1)\n",
                "    '''\n",
                "    log_ent = entropy * np.log(matrix + 1)\n",
                "    return log_ent\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "langs = [\"nl\",\"da\",\"de\",\"it\",\"es\",]\n",
                "\n",
                "model = LogisticRegression(penalty='l2',\n",
                "                           dual=False,\n",
                "                           max_iter=10000,\n",
                "                           tol=0.0001,\n",
                "                           solver='liblinear',\n",
                "                           C=1,\n",
                "                           fit_intercept=True,\n",
                "                           intercept_scaling=1.0,\n",
                "                           class_weight=None,\n",
                "                           random_state=1)\n",
                "\n",
                "cvc = CountVectorizer(max_features=300,\n",
                "                      strip_accents='unicode',\n",
                "                      ngram_range=(1, 5))\n",
                "\n",
                "ans = pd.DataFrame()\n",
                "\n",
                "\n",
                "def simpleModel(X_train, y_train, X_test):\n",
                "    print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
                "    X = cvc.fit_transform(list(X_train) + list(X_test))\n",
                "    X = log_entropy_weight(X)\n",
                "    model.fit(X[:len(X_train)], y_train)\n",
                "    res = model.predict(X[len(X_train):])\n",
                "    return res\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "working on: nl\n",
                        "sentences of 0 <= len < 1000\n",
                        "Train size: 8313, Test size: 2772\n",
                        "working on: da\n",
                        "sentences of 0 <= len < 1000\n",
                        "Train size: 8314, Test size: 2772\n",
                        "working on: de\n",
                        "sentences of 0 <= len < 1000\n",
                        "Train size: 8313, Test size: 2772\n",
                        "working on: it\n",
                        "sentences of 0 <= len < 1000\n",
                        "Train size: 8314, Test size: 2772\n",
                        "working on: es\n",
                        "sentences of 0 <= len < 1000\n",
                        "Train size: 8314, Test size: 2772\n"
                    ]
                }
            ],
            "source": [
                "for language in langs:\n",
                "    print(\"working on:\", language)\n",
                "    all_train_data = pd.read_csv(f\"../corpus/train/{language}/{language}_noent.csv\")\n",
                "    all_test_data = pd.read_csv(f\"../corpus/test/{language}/{language}_noent.csv\")\n",
                "\n",
                "    all_train_data[\"sencount\"] = all_train_data.text.str.count(\"SENTSEP\")\n",
                "    all_test_data[\"sencount\"] = all_test_data.text.str.count(\"SENTSEP\")\n",
                "    max_sen_count = max(all_train_data[\"sencount\"].max(), all_test_data[\"sencount\"].max())\n",
                "    for l, r in [(0, 1000)]:\n",
                "        print(f\"sentences of {l} <= len < {r}\")\n",
                "        train_data = all_train_data.loc[all_train_data.sencount.between(l, r, inclusive=\"left\")].copy()\n",
                "        test_data = all_test_data.loc[all_test_data.sencount.between(l, r, inclusive=\"left\")].copy()\n",
                "\n",
                "        res = simpleModel(train_data.text, train_data.label, test_data.text)\n",
                "        \n",
                "        test_data[\"label\"] = res\n",
                "        test_data = test_data.drop(\"text\", axis=1)\n",
                "        ans = pd.concat([ans, test_data])\n",
                "results = ans.copy()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "   id     label\n",
                        "0   1   England\n",
                        "0   2  Scotland\n",
                        "1   3   Ireland\n",
                        "0   4  Scotland\n",
                        "1   5  Scotland\n"
                    ]
                }
            ],
            "source": [
                "ans[\"index\"] += 1\n",
                "ans = ans.sort_values(by=[\"index\"])\n",
                "ans = ans.rename(columns={\"index\": \"id\"})\n",
                "ans = ans.drop(\"sencount\", axis=1)\n",
                "print(ans.head())\n",
                "ans.to_csv(\"../submissions/Regression_log-entropy_noent.csv\",index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "working on: nl\n",
                        "Train size: 6650, Test size: 1663\n",
                        "Train size: 6650, Test size: 1663\n",
                        "Train size: 6650, Test size: 1663\n",
                        "Train size: 6651, Test size: 1662\n",
                        "Train size: 6651, Test size: 1662\n",
                        "Acc: [0.5856885147324113, 0.5929043896572459, 0.5868911605532171, 0.598676293622142, 0.5800240673886883]\n",
                        "F1:  [0.6090175383778376, 0.6239124216793721, 0.6222150169199548, 0.6228128525914988, 0.610575325908058]\n",
                        "working on: da\n",
                        "Train size: 6651, Test size: 1663\n",
                        "Train size: 6651, Test size: 1663\n",
                        "Train size: 6651, Test size: 1663\n",
                        "Train size: 6651, Test size: 1663\n",
                        "Train size: 6652, Test size: 1662\n",
                        "Acc: [0.5880938063740229, 0.5904990980156344, 0.5850871918220084, 0.6187612748045701, 0.5992779783393501]\n",
                        "F1:  [0.613724166360979, 0.617607277019764, 0.610689746516051, 0.6442412520109636, 0.6210023844250054]\n",
                        "working on: de\n",
                        "Train size: 6650, Test size: 1663\n",
                        "Train size: 6650, Test size: 1663\n",
                        "Train size: 6650, Test size: 1663\n",
                        "Train size: 6651, Test size: 1662\n",
                        "Train size: 6651, Test size: 1662\n",
                        "Acc: [0.597714972940469, 0.5886951292844257, 0.5904990980156344, 0.5896510228640193, 0.5800240673886883]\n",
                        "F1:  [0.6226538646603085, 0.6186196788005601, 0.6259174714237189, 0.6160918497441997, 0.6036739913792643]\n",
                        "working on: it\n",
                        "Train size: 6651, Test size: 1663\n",
                        "Train size: 6651, Test size: 1663\n",
                        "Train size: 6651, Test size: 1663\n",
                        "Train size: 6651, Test size: 1663\n",
                        "Train size: 6652, Test size: 1662\n",
                        "Acc: [0.6073361395069152, 0.5923030667468431, 0.5826819001803969, 0.5935057125676488, 0.5842358604091457]\n",
                        "F1:  [0.6384736023344849, 0.6195129819352378, 0.6090168977595767, 0.619136800219338, 0.6102250266336823]\n",
                        "working on: es\n",
                        "Train size: 6651, Test size: 1663\n",
                        "Train size: 6651, Test size: 1663\n",
                        "Train size: 6651, Test size: 1663\n",
                        "Train size: 6651, Test size: 1663\n",
                        "Train size: 6652, Test size: 1662\n",
                        "Acc: [0.5706554419723392, 0.5724594107035478, 0.5953096812988575, 0.5640408899579074, 0.5938628158844765]\n",
                        "F1:  [0.6068904696158038, 0.6016895583572572, 0.6275145287693905, 0.5902548684855128, 0.6202677400832269]\n"
                    ]
                }
            ],
            "source": [
                "kfold = KFold(n_splits=5, shuffle=True, random_state=21)\n",
                "\n",
                "for language in langs:\n",
                "    print(\"working on:\", language)\n",
                "    train = pd.read_csv(f\"../corpus/train/{language}/{language}_noent.csv\")\n",
                "    acc = []\n",
                "    f1 = []\n",
                "    for train_index, test_index in kfold.split(train):\n",
                "        X_train, X_test = train.text[train_index], train.text[test_index]\n",
                "        y_train, y_test = list(train.label[train_index]), list(train.label[test_index])\n",
                "\n",
                "        res = simpleModel(X_train, y_train, X_test)\n",
                "\n",
                "        acc.append(accuracy_score(res, y_test))\n",
                "        f1.append(f1_score(res, y_test, average=\"weighted\"))\n",
                "\n",
                "    print(\"Acc:\", acc)\n",
                "    print(\"F1: \", f1)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.2 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.2"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
