{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = [stopwords.words('dutch'), stopwords.words('danish'), stopwords.words('german'), stopwords.words('italian'), stopwords.words('spanish')]\n",
    "STOPWORDS = [item for sublist in STOPWORDS for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "max_length = 500\n",
    "vocab_size = int(2/5 * (max_length * embedding_dim))\n",
    "print(vocab_size)\n",
    "\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n",
    "training_portion = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = [\"nl\", \"da\", \"de\", \"it\", \"es\", ]\n",
    "\n",
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "\n",
    "\n",
    "for language in langs:\n",
    "    train = pd.concat([train, pd.read_csv(f\"../corpus/train/{language}/{language}_plain.csv\")])\n",
    "    test = pd.concat([test, pd.read_csv(f\"../corpus/test/{language}/{language}_plain.csv\")])\n",
    "\n",
    "train.set_index(\"index\", inplace=True)\n",
    "train = train.sort_values(by=[\"index\"])\n",
    "train.reset_index(inplace=True)\n",
    "\n",
    "test.set_index(\"index\", inplace=True)\n",
    "test = test.sort_values(by=[\"index\"])\n",
    "test.reset_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.text, train.label, test_size=0.33, random_state=42, shuffle=True)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "\n",
    "label_tokenizer = Tokenizer()\n",
    "label_tokenizer.fit_on_texts(y_train)\n",
    "train_label_seq = np.array(label_tokenizer.texts_to_sequences(y_train))\n",
    "test_label_seq = np.array(label_tokenizer.texts_to_sequences(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
    "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import keras_tuner\n",
    "import keras\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Embedding(vocab_size, embedding_dim))\n",
    "    model.add(\n",
    "        layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim))\n",
    "    )\n",
    "    model.add(layers.Dense(embedding_dim, activation='relu'))\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5)\n",
    "\n",
    "tuner.search(train_padded, train_label_seq, epochs=5,  validation_data=(test_padded, test_label_seq), verbose=2)\n",
    "best_model = tuner.get_best_models()[0]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
