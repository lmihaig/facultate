{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = [stopwords.words('dutch'), stopwords.words('danish'), stopwords.words('german'), stopwords.words('italian'), stopwords.words('spanish')]\n",
    "STOPWORDS = [item for sublist in STOPWORDS for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 64\n",
    "max_length = 500\n",
    "vocab_size = int(2/5 * (max_length * embedding_dim))\n",
    "print(vocab_size)\n",
    "\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n",
    "training_portion = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = [\"nl\", \"da\", \"de\", \"it\", \"es\", ]\n",
    "\n",
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "\n",
    "\n",
    "for language in langs:\n",
    "    train = pd.concat([train, pd.read_csv(f\"../corpus/train/{language}/{language}_plain.csv\")])\n",
    "    test = pd.concat([test, pd.read_csv(f\"../corpus/test/{language}/{language}_plain.csv\")])\n",
    "\n",
    "train.set_index(\"index\", inplace=True)\n",
    "train = train.sort_values(by=[\"index\"])\n",
    "train.reset_index(inplace=True)\n",
    "\n",
    "test.set_index(\"index\", inplace=True)\n",
    "test = test.sort_values(by=[\"index\"])\n",
    "test.reset_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.text, train.label, test_size=0.33, random_state=42, shuffle=True)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "\n",
    "label_tokenizer = Tokenizer()\n",
    "label_tokenizer.fit_on_texts(y_train)\n",
    "train_label_seq = np.array(label_tokenizer.texts_to_sequences(y_train))\n",
    "test_label_seq = np.array(label_tokenizer.texts_to_sequences(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 64)          819200    \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 128)              66048     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 893,829\n",
      "Trainable params: 893,829\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
    "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 05m 39s]\n",
      "val_loss: 0.8861347436904907\n",
      "\n",
      "Best val_loss So Far: 0.8861347436904907\n",
      "Total elapsed time: 00h 05m 39s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "import keras_tuner\n",
    "import keras\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Embedding(vocab_size, embedding_dim))\n",
    "    model.add(\n",
    "        layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim))\n",
    "    )\n",
    "    model.add(layers.Dense(embedding_dim, activation='relu'))\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5)\n",
    "\n",
    "tuner.search(train_padded, train_label_seq, epochs=5,  validation_data=(test_padded, test_label_seq), verbose=2)\n",
    "best_model = tuner.get_best_models()[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5bd2b3dbaf14d82ad368ffed95420a997ad6d9e2e2e8669c1212bca174cf5f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
