{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pprint\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer, precision_score, recall_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import advertools as adv\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score,  cross_val_predict\n",
    "import seaborn as sns\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "pp = pprint.PrettyPrinter(indent=4, sort_dicts=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../corpus/nolang_dif/train_data.csv\")\n",
    "print(train_data.head())\n",
    "\n",
    "\n",
    "test_data = pd.read_csv(\"../corpus/nolang_dif/test_data.csv\")\n",
    "print(test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=21)\n",
    "model = LinearSVC(max_iter=5000, random_state=21, C=1,  penalty=\"l1\", dual=False, class_weight=\"balanced\")\n",
    "\n",
    "stop_words = []\n",
    "for key in [\"danish\", \"german\", \"dutch\", \"italian\", \"spanish\"]:\n",
    "    stop_words += list(adv.stopwords[key])\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, norm='l2', ngram_range=(1, 2), stop_words=stop_words)\n",
    "\n",
    "def simpleModel(X_train, y_train, X_test):\n",
    "    print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "    X = tfidf.fit_transform(list(X_train) + list(X_test))\n",
    "    model.fit(X[:len(X_train)], y_train)\n",
    "    res = model.predict(X[len(X_train):])\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = simpleModel(train_data.text, train_data.label, test_data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = {\"id\": test_data.index+1, \"label\": predicted_labels}\n",
    "\n",
    "submission = pd.DataFrame(data=final_data).set_index(\"id\")\n",
    "submission.head()\n",
    "submission.to_csv(f\"../submissions/nolang_SVM_tf-idf.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "f1 = []\n",
    "predicted = []\n",
    "actual = []\n",
    "\n",
    "features = np.array(train_data.text).reshape(-1, 1)\n",
    "labels = np.array(train_data.label)\n",
    "\n",
    "\n",
    "kfold_train = pd.DataFrame({\"text\": features.flatten(), \"label\":labels})\n",
    "for train_index, test_index in kfold.split(kfold_train):\n",
    "    X_train, X_test = kfold_train.text[train_index], kfold_train.text[test_index]\n",
    "    y_train, y_test = list(kfold_train.label[train_index]), list(kfold_train.label[test_index])\n",
    "\n",
    "    res = simpleModel(X_train, y_train, X_test)\n",
    "    predicted.extend(res)\n",
    "    actual.extend(y_test)\n",
    "\n",
    "    acc.append(accuracy_score(res, y_test))\n",
    "    f1.append(f1_score(res, y_test, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)\n",
    "print(\"Acc:\", np.array(acc).mean())\n",
    "print(f1)\n",
    "print(\"F1:\", np.array(f1).mean())\n",
    "label_vals = [\"England\", \"Ireland\", \"Scotland\"]\n",
    "conf_mat = confusion_matrix(actual, predicted)\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=label_vals, yticklabels=label_vals)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
