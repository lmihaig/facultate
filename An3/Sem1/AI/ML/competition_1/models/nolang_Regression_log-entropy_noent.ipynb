{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_entropy_weight(matrix):\n",
    "    if type(matrix) is not np.ndarray:\n",
    "        matrix = matrix.toarray()\n",
    "    normalized = matrix / (1 + np.sum(matrix, axis=0))\n",
    "    nr_docs, _ = matrix.shape\n",
    "    '''\n",
    "        g_i = 1 + sum     p_ij * log(p_ij + 1)   \n",
    "                 j=1,N  ------------------------\n",
    "                               log(N)                              \n",
    "    '''\n",
    "    entropy = 1 + np.sum(np.multiply(normalized, np.log(normalized + 1)), axis=0)/np.log(nr_docs)\n",
    "    '''\n",
    "        logent_ij = gi * log(tf_ij + 1)\n",
    "    '''\n",
    "    log_ent = entropy * np.log(matrix + 1)\n",
    "    return log_ent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = [\"nl\",\"da\",\"de\",\"it\",\"es\",]\n",
    "\n",
    "model = LogisticRegression(penalty='l2',\n",
    "                           dual=False,\n",
    "                           max_iter=10000,\n",
    "                           tol=0.0001,\n",
    "                           solver='liblinear',\n",
    "                           C=1,\n",
    "                           fit_intercept=True,\n",
    "                           intercept_scaling=1.0,\n",
    "                           class_weight=None,\n",
    "                           random_state=1)\n",
    "\n",
    "cvc = CountVectorizer(max_features=500,\n",
    "                      ngram_range=(1, 5))\n",
    "\n",
    "ans = pd.DataFrame()\n",
    "\n",
    "\n",
    "def simpleModel(X_train, y_train, X_test):\n",
    "    print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "    X = cvc.fit_transform(list(X_train) + list(X_test))\n",
    "    X = log_entropy_weight(X)\n",
    "    model.fit(X[:len(X_train)], y_train)\n",
    "    res = model.predict(X[len(X_train):])\n",
    "    return res\n",
    "\n",
    "acc = []\n",
    "f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data = pd.DataFrame()\n",
    "all_test_data = pd.DataFrame()\n",
    "\n",
    "for language in langs:\n",
    "    all_train_data = pd.concat([all_train_data, pd.read_csv(f\"../corpus/train/{language}/{language}_noent.csv\")])\n",
    "    all_test_data = pd.concat([all_test_data, pd.read_csv(f\"../corpus/test/{language}/{language}_noent.csv\")])\n",
    "\n",
    "all_train_data[\"sencount\"] = all_train_data.text.str.count(\"SENTSEP\")\n",
    "all_test_data[\"sencount\"] = all_test_data.text.str.count(\"SENTSEP\")\n",
    "\n",
    "max_sen_count = max(all_train_data[\"sencount\"].max(), all_test_data[\"sencount\"].max())\n",
    "for l,r in [(0,1000)]:\n",
    "    print(f\"sentences of {l} <= len < {r}\")\n",
    "    train_data = all_train_data.loc[all_train_data.sencount.between(l, r, inclusive=\"left\")].copy()\n",
    "    test_data = all_test_data.loc[all_test_data.sencount.between(l, r, inclusive=\"left\")].copy()\n",
    "\n",
    "    res = simpleModel(train_data.text, train_data.label, test_data.text)\n",
    "    test_data[\"label\"] = res\n",
    "    test_data = test_data.drop(\"text\", axis=1)\n",
    "    ans = pd.concat([ans, test_data])\n",
    "\n",
    "results = ans.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans[\"index\"] += 1\n",
    "ans = ans.sort_values(by=[\"index\"])\n",
    "ans = ans.rename(columns={\"index\": \"id\"})\n",
    "ans = ans.drop(\"sencount\", axis=1)\n",
    "print(ans.head())\n",
    "ans.to_csv(\"../submissions/nolang_Regression_log-entropy_noent.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=21)\n",
    "\n",
    "train = pd.DataFrame()\n",
    "\n",
    "for language in langs:\n",
    "    train = pd.concat([all_train_data, pd.read_csv(f\"../corpus/train/{language}/{language}_noent.csv\")])\n",
    "\n",
    "train.set_index(\"index\", inplace=True)\n",
    "train = train.sort_values(by=[\"index\"])\n",
    "train.reset_index(inplace=True)\n",
    "\n",
    "acc = []\n",
    "f1 = []\n",
    "for train_index, test_index in kfold.split(train):\n",
    "    X_train, X_test = train.text[train_index], train.text[test_index]\n",
    "    y_train, y_test = train.label[train_index], train.label[test_index]\n",
    "\n",
    "    X = cvc.fit_transform(list(X_train) + list(X_test))\n",
    "    X = log_entropy_weight(X)\n",
    "\n",
    "    model.fit(X[:len(X_train)], y_train)\n",
    "    res = model.predict(X[len(X_train):])\n",
    "    acc.append(accuracy_score(res, y_test))\n",
    "    f1.append(f1_score(res, y_test, average='weighted'))\n",
    "print(\"Acc:\", acc)\n",
    "print(\"F1: \", f1)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
